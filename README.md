# ğŸš€ llm-enterprise-security-architecture: Protegiendo el Cerebro Digital Empresarial

[![License: MIT](https://img.shields.io/badge/License-MIT-yellow.svg)](https://opensource.org/licenses/MIT)
[![Python 3.10+](https://img.shields.io/badge/python-3.10+-blue.svg)](https://www.python.org/downloads/)
[![Security: bandit](https://img.shields.io/badge/security-bandit-yellow.svg)](https://github.com/PyCQA/bandit)
[![Code style: black](https://img.shields.io/badge/code%20style-black-000000.svg)](https://github.com/psf/black)

Este repositorio complementa la serie de artÃ­culos **"Del Prompt al Compliance"** de **[JosÃ© Cazorla](https://www.linkedin.com/in/jose-cazorla/recent-activity/articles/)** en LinkedIn, proporcionando ejemplos prÃ¡cticos y configuraciones para implementar una arquitectura de seguridad robusta para Large Language Models (LLMs) en entornos empresariales.

En la era de la IA Generativa, la seguridad ya no es una opciÃ³n, sino una necesidad imperativa. AquÃ­ encontrarÃ¡s cÃ³mo traducir los principios de DevSecOps, MLOps y gobernanza en soluciones tÃ©cnicas concretas para proteger tus LLMs, datasets y pipelines.

ğŸš§ **En construcciÃ³n** Â· ğŸ§© Contenido incompleto Â· ğŸ”œ MÃ¡s actualizaciones pronto

---

## ğŸ’¡ El Problema: Un Nuevo PerÃ­metro de Ataque

La adopciÃ³n de LLMs introduce vectores de ataque sin precedentes:

- **ğŸ£ Prompt Injection**: ManipulaciÃ³n maliciosa de las instrucciones del modelo
- **ğŸ”“ Data Exfiltration**: Robo de informaciÃ³n sensible a travÃ©s de respuestas del LLM
- **ğŸ§© Model Theft**: ExtracciÃ³n de los pesos del modelo mediante consultas adversarias
- **ğŸ” Training Data Poisoning**: ContaminaciÃ³n de datasets con datos maliciosos
- **âš¡ Supply Chain Attacks**: Compromiso de modelos pre-entrenados o librerÃ­as

Las defensas de seguridad tradicionales son insuficientes. Necesitamos una estrategia adaptada que considere la naturaleza probabilÃ­stica y los ciclos de vida especÃ­ficos de la IA.

---

## ğŸ¯ Nuestra SoluciÃ³n: Una Arquitectura de Defensa en Profundidad

Proponemos una arquitectura multicapa que integra controles en todo el ciclo de vida del modelo:

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                    ğŸŒ USUARIOS / APLICACIONES                    â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                           â”‚
                           â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                     ğŸ›¡ï¸ AI GATEWAY / PROXY                       â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”           â”‚
â”‚  â”‚ Prompt      â”‚  â”‚ DLP         â”‚  â”‚ Rate         â”‚           â”‚
â”‚  â”‚ Injection   â”‚  â”‚ Filtering   â”‚  â”‚ Limiting     â”‚           â”‚
â”‚  â”‚ Detection   â”‚  â”‚             â”‚  â”‚              â”‚           â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜           â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                           â”‚
                           â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                    ğŸ¤– LLM (GPT-4, Claude, etc.)                 â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                           â”‚
                           â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                    ğŸ“Š VECTOR DATABASE (RAG)                      â”‚
â”‚                    + RBAC Policies                               â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                           â”‚
        â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
        â–¼                  â–¼                  â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ ğŸ” Cranium    â”‚  â”‚ ğŸš¨ Darktrace â”‚  â”‚ ğŸ“ˆ Prometheus   â”‚
â”‚ (Governance)  â”‚  â”‚ (Detection)  â”‚  â”‚ (Monitoring)    â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

---

## ğŸ› ï¸ Componentes Clave y Ejemplos PrÃ¡cticos

### 1. ğŸ›¡ï¸ El AI Gateway/Proxy: Nuestro "LLM Firewall"

El AI Gateway es el punto de control crÃ­tico que inspecciona y filtra las interacciones con tus LLMs.

**Archivos principales:**
- [`src/ai_gateway_proxy/main.py`](src/ai_gateway_proxy/main.py) - Proxy FastAPI con flujo de seguridad completo
- [`src/ai_gateway_proxy/prompt_injection_filters.py`](src/ai_gateway_proxy/prompt_injection_filters.py) - Detector multicapa de Prompt Injection
- [`src/ai_gateway_proxy/dlp_filters.py`](src/ai_gateway_proxy/dlp_filters.py) - EscÃ¡ner DLP para PII

**Funcionalidades:**
- âœ… DetecciÃ³n de Prompt Injection con mÃºltiples heurÃ­sticas
- âœ… Escaneo DLP para PII (correos, telÃ©fonos, SSN, tarjetas de crÃ©dito, etc.)
- âœ… Rate limiting por usuario
- âœ… Logging y auditorÃ­a completa
- âœ… MÃ©tricas de seguridad en tiempo real

**Ejemplo de uso:**

```bash
# Iniciar el AI Gateway
cd src/ai_gateway_proxy
uvicorn main:app --reload --port 8080

# Probar con curl
curl -X POST "http://localhost:8080/v1/chat/completions" \
  -H "Content-Type: application/json" \
  -d '{
    "prompt": "Â¿CuÃ¡l es la capital de Francia?",
    "user_id": "user123",
    "model": "gpt-4"
  }'
```

**Flujo de seguridad:**

```
Solicitud â†’ Prompt Injection Check â†’ DLP Input Scan â†’ LLM Call 
         â†’ DLP Output Scan â†’ Response â†’ Audit Log
```

---

### 2. ğŸ”’ Seguridad en MLOps: Blindando la Cadena de Suministro de la IA

La seguridad debe integrarse en cada paso del ciclo de vida del modelo. Esto es **DevSecLLMOps** en acciÃ³n.

**Pipeline de CI/CD:**
- [`.github/workflows/devsecllmops-pipeline.yml`](.github/workflows/devsecllmops-pipeline.yml) - Pipeline completo con escaneos de seguridad

**Scripts de MLOps:**
- [`src/mlops_scripts/scan_model_artifact.py`](src/mlops_scripts/scan_model_artifact.py) - EscÃ¡ner de artefactos de modelos (.pkl, .safetensors, .h5)
- [`src/mlops_scripts/check_dataset_lineage.py`](src/mlops_scripts/check_dataset_lineage.py) - Verificador de trazabilidad de datasets

**Controles de seguridad implementados:**

1. **ğŸ” Escaneo de Dependencias**: Snyk/Trivy para vulnerabilidades
2. **ğŸ” Escaneo de Modelos**: DetecciÃ³n de cÃ³digo malicioso en pickles
3. **ğŸ“Š VerificaciÃ³n de Lineage**: ValidaciÃ³n de origen y compliance de datasets
4. **ğŸ³ Escaneo de Contenedores**: Trivy para imÃ¡genes Docker
5. **ğŸ“‹ Registro en Cranium**: Inventario de activos AI y AI-BOM

**Ejemplo: Escanear un artefacto de modelo**

```bash
python src/mlops_scripts/scan_model_artifact.py models/my_model.pkl

# Output:
# ======================================================================
#   REPORTE DE ESCANEO DE SEGURIDAD - ARTEFACTO ML
# ======================================================================
# 
# Archivo: models/my_model.pkl
# Tipo: pickle
# SHA-256: abc123...
# 
# RESULTADO: âœ— NO SEGURO
# Nivel de Riesgo: CRITICAL
# 
# ğŸš¨ AMENAZAS DETECTADAS (2):
#   1. âš ï¸ CRÃTICO: MÃ³dulo peligroso encontrado: 'os'
#   2. âš ï¸ ALTO: OperaciÃ³n sospechosa encontrada: exec
```

**Ejemplo: Verificar lineage de un dataset**

```bash
# Crear template de metadatos
python src/mlops_scripts/check_dataset_lineage.py --create-template

# Verificar compliance
python src/mlops_scripts/check_dataset_lineage.py data/training_data_metadata.json
```

---

### 3. ğŸ“‹ Gobernanza y Monitoreo: La Visibilidad que Necesitas

Para proteger lo que no conoces, necesitas visibilidad.

**PolÃ­ticas RBAC:**
- [`policies/rbac_vector_db.yaml`](policies/rbac_vector_db.yaml) - Control de acceso para Vector DB

**CaracterÃ­sticas de la polÃ­tica RBAC:**
- âœ… Roles granulares (admin, ml-engineer, data-scientist, llm-app, etc.)
- âœ… ClasificaciÃ³n de datos por sensibilidad (public, internal, confidential, restricted)
- âœ… Control de acceso dinÃ¡mico basado en contexto (horario, geolocalizaciÃ³n, etc.)
- âœ… Rate limiting por rol
- âœ… AuditorÃ­a completa de accesos
- âœ… Manejo de PII con auto-detecciÃ³n
- âœ… IntegraciÃ³n con AI Gateway para propagaciÃ³n de contexto

**Ejemplo de polÃ­tica:**

```yaml
- name: llm-application-prod
  permissions:
    - resource: "vectors/public/*"
      actions: [read]
    - resource: "vectors/user-specific/{user_id}/*"
      actions: [read, create, update]
  conditions:
    authentication_method: "certificate"
    pii_filtering: true
  rate_limits:
    requests_per_minute: 10000
  data_filtering:
    exclude_collections: ["hr-data", "financial-records"]
```

---

## ğŸš€ CÃ³mo Empezar

### Paso 1: Clonar el Repositorio

```bash
git clone https://github.com/tu-usuario/llm-enterprise-security-architecture.git
cd llm-enterprise-security-architecture
```

### Paso 2: Configurar el Entorno

```bash
# Crear entorno virtual
python -m venv venv
source venv/bin/activate  # En Windows: venv\Scripts\activate

# Instalar dependencias
pip install -r requirements.txt

# Instalar modelo de SpaCy para PII detection (opcional)
python -m spacy download en_core_web_sm
```

### Paso 3: ConfiguraciÃ³n

Crea un archivo `.env` con tus credenciales:

```bash
# LLM API Keys
OPENAI_API_KEY=sk-...
ANTHROPIC_API_KEY=sk-ant-...

# Governance & Security
CRANIUM_API_URL=https://cranium.company.com/api/v1
CRANIUM_API_KEY=...

# Vector DB
PINECONE_API_KEY=...
PINECONE_ENVIRONMENT=...

# Monitoring
PROMETHEUS_GATEWAY=...
```

### Paso 4: Ejecutar el AI Gateway

```bash
cd src/ai_gateway_proxy
uvicorn main:app --reload --host 0.0.0.0 --port 8080
```

Accede a la documentaciÃ³n interactiva en: `http://localhost:8080/docs`

### Paso 5: Integrar en tu Pipeline CI/CD

Copia el workflow de ejemplo a tu repositorio:

```bash
cp .github/workflows/devsecllmops-pipeline.yml .github/workflows/
```

Configura los secrets necesarios en GitHub:
- `SNYK_TOKEN`
- `CRANIUM_API_KEY`
- `CRANIUM_API_URL`

---

## ğŸ“¦ Estructura del Proyecto

```
llm-enterprise-security-architecture/
â”œâ”€â”€ .github/
â”‚   â””â”€â”€ workflows/
â”‚       â””â”€â”€ devsecllmops-pipeline.yml    # Pipeline DevSecLLMOps
â”œâ”€â”€ docs/
â”‚   â””â”€â”€ architecture_diagram.png          # Diagrama de arquitectura
â”‚   â””â”€â”€ ai_gateway_flow.png               # Flujo del AI Gateway
â”œâ”€â”€ src/
â”‚   â”œâ”€â”€ ai_gateway_proxy/
â”‚   â”‚   â”œâ”€â”€ main.py                       # AI Gateway FastAPI
â”‚   â”‚   â”œâ”€â”€ prompt_injection_filters.py   # Detector de Prompt Injection
â”‚   â”‚   â””â”€â”€ dlp_filters.py                # EscÃ¡ner DLP
â”‚   â””â”€â”€ mlops_scripts/
â”‚       â”œâ”€â”€ scan_model_artifact.py        # EscÃ¡ner de modelos
â”‚       â””â”€â”€ check_dataset_lineage.py      # Verificador de lineage
â”œâ”€â”€ policies/
â”‚   â””â”€â”€ rbac_vector_db.yaml               # PolÃ­tica RBAC
â”œâ”€â”€ models/                                # (Tus modelos aquÃ­)
â”œâ”€â”€ data/                                  # (Tus datasets aquÃ­)
â”œâ”€â”€ tests/                                 # Tests unitarios
â”œâ”€â”€ README.md                              # Este archivo
â”œâ”€â”€ requirements.txt                       # Dependencias Python
â””â”€â”€ LICENSE                                # Licencia MIT
```

---

## ğŸ§ª Testing

Ejecutar los tests:

```bash
# Todos los tests
pytest

# Con cobertura
pytest --cov=src --cov-report=html

# Solo tests de seguridad
pytest tests/security/
```

---

## ğŸ” Mejores PrÃ¡cticas de Seguridad

### Para el AI Gateway:
1. **Siempre** ejecuta el gateway en modo HTTPS en producciÃ³n
2. Implementa **autenticaciÃ³n robusta** (OAuth 2.0, mTLS)
3. Configura **rate limiting** agresivo para prevenir abusos
4. Habilita **logging exhaustivo** pero redacta PII automÃ¡ticamente
5. Integra con un **SIEM** para correlaciÃ³n de eventos

### Para MLOps:
1. **Nunca** deserialices pickles no confiables
2. Usa **safetensors** en lugar de pickle cuando sea posible
3. **Firma criptogrÃ¡ficamente** todos los artefactos de modelos
4. Implementa **escaneo obligatorio** en el pipeline CI/CD
5. MantÃ©n un **inventario completo** de datasets y modelos

### Para Vector DBs:
1. Implementa **RBAC estricto** segÃºn el principio de mÃ­nimo privilegio
2. **Cifra** datos en reposo y en trÃ¡nsito (TLS 1.3+)
3. Habilita **auditorÃ­a** de todos los accesos a datos sensibles
4. Usa **aislamiento por namespace** para diferentes aplicaciones
5. Implementa **filtrado dinÃ¡mico** basado en el contexto del usuario

---

## ğŸ¤ IntegraciÃ³n con Herramientas Empresariales

### Cranium (AI Governance)
```python
# Registro de modelo en Cranium
cranium_client.register_model(
    name="chatbot-v2",
    version="2.1.0",
    risk_assessment={"score": "low"},
    datasets_used=["customer-faq-v1"],
    compliance_status={"gdpr": True, "soc2": True}
)
```

### Darktrace (Threat Detection)
```python
# Enviar eventos de seguridad a Darktrace
darktrace_client.send_event({
    "type": "prompt_injection_attempt",
    "severity": "high",
    "user_id": "user123",
    "timestamp": datetime.utcnow()
})
```

### Prometheus (Monitoring)
```python
from prometheus_client import Counter

prompt_injection_attempts = Counter(
    'prompt_injection_attempts_total',
    'Total prompt injection attempts detected'
)

# Incrementar mÃ©trica
prompt_injection_attempts.inc()
```

---

## ğŸ“š Recursos Adicionales

### ArtÃ­culos de la Serie "Del Prompt al Compliance":
- [Parte 1: IntroducciÃ³n](https://www.linkedin.com/pulse/del-prompt-al-compliance-arquitectura-de-seguridad-jose-cazorla-gij%C3%B3n-eraff)
- [Parte 2: Arquitectura de Seguridad]()
- [Parte 3: MLOps Seguro]()


### DocumentaciÃ³n Recomendada:
- [OWASP Top 10 for LLMs](https://owasp.org/www-project-top-10-for-large-language-model-applications/)
- [NIST AI Risk Management Framework](https://www.nist.gov/itl/ai-risk-management-framework)
- [Microsoft Presidio (PII Detection)](https://microsoft.github.io/presidio/)
- [HiddenLayer Model Scanner](https://hiddenlayer.com/)

---

## ğŸ’¬ ContribuciÃ³n y Feedback

Â¡Tu experiencia es valiosa! Si tienes ideas para mejorar estos ejemplos, sugerencias para nuevos controles o has encontrado un error, no dudes en:

- ğŸ› Abrir un **Issue** para reportar bugs
- ğŸ’¡ Enviar un **Pull Request** con mejoras
- ğŸ’¬ Compartir tu experiencia implementando estos controles
- â­ Dar una estrella al repo si te ha sido Ãºtil

### Contribuir:

```bash
# 1. Fork el repositorio
# 2. Crea una rama para tu feature
git checkout -b feature/mi-nueva-funcionalidad

# 3. Commit tus cambios
git commit -am "AÃ±ade nueva funcionalidad X"

# 4. Push a la rama
git push origin feature/mi-nueva-funcionalidad

# 5. Abre un Pull Request
```

---

## ğŸ›¡ï¸ Seguridad y Responsabilidad

Este proyecto tiene fines educativos y de referencia. 


---

## ğŸ“„ Licencia

Este proyecto estÃ¡ bajo la licencia [MIT License](LICENSE).

```
MIT License

Copyright (c) 2025 JosÃ© Cazorla GijÃ³n

Permission is hereby granted, free of charge, to any person obtaining a copy
of this software and associated documentation files (the "Software"), to deal
in the Software without restriction, including without limitation the rights
to use, copy, modify, merge, publish, distribute, sublicense, and/or sell
copies of the Software...
```

---

## ğŸ™ Agradecimientos

- A la comunidad de **OWASP** por sus guÃ­as sobre LLM Security
- A **Microsoft** por Presidio y herramientas de PII detection
- A **Anthropic** y **OpenAI** por sus investigaciones en AI Safety
- A todos los contribuidores que hacen posible este proyecto

---




<div align="center">

**â­ Si este proyecto te ayuda a proteger tus LLMs, considera darle una estrella â­**

*Construyendo juntos una comunidad mÃ¡s segura para la IA*

</div>
